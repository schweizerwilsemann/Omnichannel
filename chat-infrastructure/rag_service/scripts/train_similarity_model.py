from __future__ import annotations

import argparse
import json
from pathlib import Path
from typing import Iterable, List

from sentence_transformers import InputExample, SentenceTransformer, losses
from torch.utils.data import DataLoader


def load_triplets(path: Path) -> List[InputExample]:
    examples: List[InputExample] = []
    with path.open("r", encoding="utf-8") as handle:
        for line in handle:
            record = json.loads(line)
            texts = [record["anchor"], record["positive"]]
            if "negative" in record:
                texts.append(record["negative"])
            examples.append(InputExample(texts=texts))
    return examples


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Fine-tune a sentence-transformer for menu similarity.")
    parser.add_argument("--pairs", required=True, help="Path to JSONL triplets generated by generate_similarity_pairs.py")
    parser.add_argument("--model-name", default="sentence-transformers/all-MiniLM-L6-v2")
    parser.add_argument("--loss", choices=["mnr", "triplet"], default="mnr", help="Loss function: multiple negative ranking or triplet.")
    parser.add_argument("--output", required=True, help="Directory to store fine-tuned model")
    parser.add_argument("--batch-size", type=int, default=32)
    parser.add_argument("--epochs", type=int, default=2)
    parser.add_argument("--lr", type=float, default=2e-5)
    parser.add_argument("--warmup-ratio", type=float, default=0.1)
    return parser.parse_args()


def main() -> None:
    args = parse_args()
    data_path = Path(args.pairs)
    examples = load_triplets(data_path)
    if not examples:
        raise SystemExit("No training examples found.")

    model = SentenceTransformer(args.model_name)
    loader = DataLoader(examples, shuffle=True, batch_size=args.batch_size)

    if args.loss == "triplet":
        train_loss = losses.TripletLoss(
            model,
            distance_metric=losses.TripletDistanceMetric.COSINE,
            triplet_margin=0.3,
        )
    else:
        # MultipleNegativesRankingLoss expects only anchor/positive texts
        # Strip negatives if present
        normalized_examples = []
        for example in examples:
            normalized_examples.append(InputExample(texts=example.texts[:2]))
        loader = DataLoader(normalized_examples, shuffle=True, batch_size=args.batch_size)
        train_loss = losses.MultipleNegativesRankingLoss(model)

    total_steps = len(loader) * args.epochs
    warmup_steps = int(total_steps * args.warmup_ratio)

    model.fit(
        train_objectives=[(loader, train_loss)],
        epochs=args.epochs,
        warmup_steps=warmup_steps,
        optimizer_params={"lr": args.lr},
        show_progress_bar=True,
        output_path=args.output,
    )

    print(f"Model saved to {args.output}")


if __name__ == "__main__":
    main()
